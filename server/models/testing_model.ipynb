{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FACE DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('/Users/ceo/Desktop/CTP_DATASCI_FRIDAY/final_project/server/data/testing_images/testing_image.jpg')\n",
    "cv2.imshow('image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load cascade classifer - frontalface\n",
    "face_cascade = cv2.CascadeClassifier('/Users/ceo/Desktop/CTP_DATASCI_FRIDAY/final_project/server/data/cascades/haarcascade_frontalface_default.xml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply cascade classifer to an image\n",
    "faces, num_detection = face_cascade.detectMultiScale2(img, minNeighbors=5, scaleFactor=1.12, minSize=(30,30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[369 504 267 267]\n",
      " [591 872 258 258]]\n"
     ]
    }
   ],
   "source": [
    "print(faces) #The coordinates of the detected faces basically is a rectangle around the face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18 10]\n"
     ]
    }
   ],
   "source": [
    "print(num_detection) #The number of points that were matched to detect the face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y, w, h in faces:\n",
    "    pt1 = (x, y)\n",
    "    pt2 = (x + w, y + h)\n",
    "    cv2.rectangle(img, pt1, pt2, (255, 0, 0), 2)  # Blue rectangles\n",
    "\n",
    "cv2.imshow('image', img)\n",
    "cv2.waitKey(0) & 0xFF\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Draw the circle\n",
    "cx = x + w//2 #Center x coordinate calculates by: the x position of the face + the width of the face divided by 2\n",
    "cy = y + h//2 #Center y coordinate calculates by: the y position of the face + the height of the face divided by 2\n",
    "r = w//2 #Radius of the circle is the width of the face divided by 2\n",
    "\n",
    "cv2.circle(img, (cx,cy), r, (0,255,0), 3)\n",
    "cv2.imshow('face detection circle', img)\n",
    "key = cv2.waitKey(0) & 0xFF\n",
    "if key == ord('q'):\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Faces Detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('/Users/ceo/Desktop/CTP_DATASCI_FRIDAY/final_project/server/data/testing_images/friends_img.jpg')\n",
    "\n",
    "\n",
    "cv2.imshow('image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[162  22  37  37]\n",
      " [219  32  50  50]\n",
      " [ 98  24  57  57]]\n",
      "[[166  19  42  42]\n",
      " [227  31  51  51]\n",
      " [104  21  66  66]]\n"
     ]
    }
   ],
   "source": [
    "face_cascade = cv2.CascadeClassifier('/Users/ceo/Desktop/CTP_DATASCI_FRIDAY/final_project/server/data/cascades/haarcascade_frontalface_default.xml')\n",
    "profile_cascade = cv2.CascadeClassifier('/Users/ceo/Desktop/CTP_DATASCI_FRIDAY/final_project/server/data/cascades/haarcascade_profileface.xml')\n",
    "\n",
    "faces_frontal, num_detection_frontal = face_cascade.detectMultiScale2(img, minNeighbors=2, scaleFactor=1.05, minSize=(10,10))\n",
    "\n",
    "faces_profile , num_detection_profile = profile_cascade.detectMultiScale2(img, minNeighbors=2, scaleFactor=1.05, minSize=(10,10))\n",
    "\n",
    "\n",
    "#Draw the rectangle around the face_profiles\n",
    "for x, y, w, h in faces_frontal:\n",
    "    pt1 = (x, y)\n",
    "    pt2 = (x + w, y + h)\n",
    "    cv2.rectangle(img, pt1, pt2, (255, 0, 0), 1)  # Blue rectangles\n",
    "\n",
    "\n",
    "print(faces_frontal)\n",
    "print(faces_profile)\n",
    "# cv2.imshow('image', img)\n",
    "# cv2.waitKey(0) & 0xFF\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faces & Eyes Detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('/Users/ceo/Desktop/CTP_DATASCI_FRIDAY/final_project/server/data/testing_images/testing_image.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('/Users/ceo/Desktop/CTP_DATASCI_FRIDAY/final_project/server/data/cascades/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('/Users/ceo/Desktop/CTP_DATASCI_FRIDAY/final_project/server/data/cascades/haarcascade_eye.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8 9]\n",
      "[29 19]\n",
      "[48]\n"
     ]
    }
   ],
   "source": [
    "faces, num_detection = face_cascade.detectMultiScale2(img, scaleFactor=1.1, minSize=(10,10), minNeighbors=5)\n",
    "print(num_detection)\n",
    "for x,y,w,h in faces:\n",
    "    cv2.rectangle(img, (x,y), (x+w, y+h), (0,255,0))\n",
    "\n",
    "    #Cropping the face\n",
    "    face_roi = img[y:y+h, x:x+w] #Region of interest used for cropping the image, where the row goes first and then the column so then the y coordinate goes first and then the x coordinate\n",
    "    #apply cascade classifer to eyes\n",
    "    eyes, num_detection_eyes = eye_cascade.detectMultiScale2(face_roi, scaleFactor=1.1, minSize=(10,10), minNeighbors=4)\n",
    "    print(num_detection_eyes)\n",
    "    #Draw the circle around the eyes\n",
    "    for ex,ey,ew,eh in eyes:\n",
    "        cx = x + ex + ew//2 #Add x since we need the entire image coordinates\n",
    "        cy = y + ey + eh//2 #Add y since we need the entire image coordinates\n",
    "        r = eh//2 \n",
    "        cv2.circle(img, (cx,cy), r, (0,255,0), 2)\n",
    "\n",
    "# #Display the image\n",
    "cv2.imshow('face, eyes detection', img)\n",
    "cv2.waitKey(0) & 0xFF\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face, Eyes, Smile Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('/Users/ceo/Desktop/CTP_DATASCI_FRIDAY/final_project/server/data/testing_images/testing_image.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('/Users/ceo/Desktop/CTP_DATASCI_FRIDAY/final_project/server/data/cascades/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('/Users/ceo/Desktop/CTP_DATASCI_FRIDAY/final_project/server/data/cascades/haarcascade_eye.xml')\n",
    "smile_cascade = cv2.CascadeClassifier('/Users/ceo/Desktop/CTP_DATASCI_FRIDAY/final_project/server/data/cascades/haarcascade_smile.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8 9]\n",
      "[29 19]\n",
      "[80]\n"
     ]
    }
   ],
   "source": [
    "faces, num_detection = face_cascade.detectMultiScale2(img, scaleFactor=1.1, minSize=(10,10), minNeighbors=5)\n",
    "print(num_detection)\n",
    "\n",
    "\n",
    "for x,y,w,h in faces[0:1]:\n",
    "    face_roi = img[y:y+h, x:x+w].copy() #Region of interest used for cropping the image, where the row goes first and then the column so then the y coordinate goes first and then the x coordinate\n",
    "    cv2.rectangle(img, (x,y), (x+w, y+h), (0,255,0))\n",
    "\n",
    "    #apply cascade classifer to eyes\n",
    "    eyes, num_detection_eyes = eye_cascade.detectMultiScale2(face_roi, scaleFactor=1.1, minSize=(10,10), minNeighbors=4)\n",
    "    print(num_detection_eyes)\n",
    "    #Draw the circle around the eyes\n",
    "    for ex,ey,ew,eh in eyes:\n",
    "        cx = x + ex + ew//2 #Add x since we need the entire image coordinates\n",
    "        cy = y + ey + eh//2 #Add y since we need the entire image coordinates\n",
    "        r = eh//2 \n",
    "        cv2.circle(img, (cx,cy), r, (0,255,0), 2)\n",
    "\n",
    "    #apply cascade classifer to smile\n",
    "    smile, num_detection_smile = smile_cascade.detectMultiScale2(face_roi, scaleFactor=1.2, minSize=(20,20), minNeighbors=8)\n",
    "    for sx,sy,sw,sh in smile:\n",
    "        cv2.rectangle(img,(x+sx, y + sy), (x+sx+sw, y+sy+sh), (0,255,0), 2) #the (x+sx+sw, y+sy+sh) is the diagonal line of the rectangle\n",
    "\n",
    "    print(num_detection_smile)\n",
    "#Display the image\n",
    "cv2.imshow('face, eyes detection', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Detection DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('/Users/ceo/Desktop/CTP_DATASCI_FRIDAY/final_project/server/data/testing_images/friends_img.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the model\n",
    "\n",
    "net = cv2.dnn.readNetFromCaffe('/Users/ceo/Desktop/CTP_DATASCI_FRIDAY/final_project/server/models/saved_models/deploy.prototxt.txt',\n",
    "                                '/Users/ceo/Desktop/CTP_DATASCI_FRIDAY/final_project/server/models/saved_models/res10_300x300_ssd_iter_140000.caffemodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract blob with DNN\n",
    "blob = cv2.dnn.blobFromImage(img, 1, (300,300),  (104, 177, 123), swapRB=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the blob to model, set blob as input\n",
    "net.setInput(blob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the model\n",
    "detection = net.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 200, 7)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detection.shape\n",
    "\n",
    "#1 , 1, 200 , 7 -> 200 is the faces detected, 7 is the number of: (0: Image number, 1: Binary(0,1), 2: Confidence Score (0 -1), 3-6: Bounding box coordinates(3: Start x, 4: Start y, 5: End x, 6: End y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99997556\n",
      "0.99990284\n",
      "0.9700988\n",
      "0.9383159\n"
     ]
    }
   ],
   "source": [
    "h, w = img.shape[:2]\n",
    "\n",
    "for i in range(0, detection.shape[2]):\n",
    "    confidence = detection[0,0,i,2]\n",
    "    if confidence > 0.5:\n",
    "        box = detection[0,0,i,3:7] * np.array([w,h,w,h])\n",
    "        (startX, startY, endX, endY) = box.astype('int')\n",
    "        cv2.rectangle(img, (startX, startY), (endX, endY), (255,0,0), 2)\n",
    "\n",
    "        #Put text\n",
    "        cv2.putText(img, 'face: {:.2f}%'.format(confidence * 100), (startX, startY-10), cv2.FONT_HERSHEY_PLAIN, 0.45, (0,0,255),)\n",
    "        print(confidence)\n",
    "cv2.imshow('face detection', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction from Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
